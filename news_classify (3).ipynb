{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "I was trying to **use only the title and category column** to build the classifier. Considering that these news (data) are taken from the Internet, I am focusing to build the model with the help of keywords in the title. **Here is the deal...**\n",
    "\n",
    "Optimizing blog posts for keywords is not about incorporating as many keywords into posts as possible. Turns out that'll actually hurt the SEO efforts, because search engines will think you're keyword stuffing (i.e., including your keywords as much as possible with the sole purpose of gaining ranking in organic search). A good rule of thumb is **to focus** on one or two keywords per blog post. This'll help keep you focused on a goal for your post. While you can use more than one keyword in a single post, keep the focus of the post narrow enough to allow you to spend time actually optimizing for just one or two keywords.\n",
    "\n",
    "Though contents (body) also involved, but mostly, the title (i.e., headline) of a blog post will be a search engine's and reader's first step in determining the relevancy of your content, so including a keyword here is vital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): textblob in c:\\users\\zef\\anaconda2\\lib\\site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk>=3.1 in c:\\users\\zef\\anaconda2\\lib\\site-packages (from textblob)\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk in c:\\users\\zef\\anaconda2\\lib\\site-packages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "\n",
    "def install_lib(package):\n",
    "    return pip.main(['install', package])\n",
    "\n",
    "install_lib(\"textblob\")\n",
    "install_lib(\"nltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import textblob\n",
    "\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from nltk.classify import PositiveNaiveBayesClassifier\n",
    "\n",
    "# Locked and load Check\n",
    "df = pandas.read_json(\"articles.json\")\n",
    "stopwords = pandas.read_csv(\"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tekno</td>\n",
       "      <td>Liputan6.com, Jakarta - Pertumbuhan startup te...</td>\n",
       "      <td>Kiat Sukses Berbisnis Teknologi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>By Eri Komar Sinaga Mantan Kepala Biro Adminis...</td>\n",
       "      <td>KPK Periksa Politikus Demokrat Terkait Korupsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>JAKARTA - Komisi Pemilihan Umum (KPU) DKI Jaka...</td>\n",
       "      <td>Pendaftaran Ditutup, KPU Pastikan Pilgub DKI D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tekno</td>\n",
       "      <td>ArenaLTE.com - Perkuat industri gaming yang se...</td>\n",
       "      <td>Perkuat Industri Gaming, AMD Akuisisi Pengemba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>VIVA.co.id - Hingga Senin malam, 26 September ...</td>\n",
       "      <td>Bertambah, Korban Tewas Banjir Garut Jadi 34 O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text  \\\n",
       "0    Tekno  Liputan6.com, Jakarta - Pertumbuhan startup te...   \n",
       "1     News  By Eri Komar Sinaga Mantan Kepala Biro Adminis...   \n",
       "2     News  JAKARTA - Komisi Pemilihan Umum (KPU) DKI Jaka...   \n",
       "3    Tekno  ArenaLTE.com - Perkuat industri gaming yang se...   \n",
       "4     News  VIVA.co.id - Hingga Senin malam, 26 September ...   \n",
       "\n",
       "                                               title  \n",
       "0                    Kiat Sukses Berbisnis Teknologi  \n",
       "1  KPK Periksa Politikus Demokrat Terkait Korupsi...  \n",
       "2  Pendaftaran Ditutup, KPU Pastikan Pilgub DKI D...  \n",
       "3  Perkuat Industri Gaming, AMD Akuisisi Pengemba...  \n",
       "4  Bertambah, Korban Tewas Banjir Garut Jadi 34 O...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['title'] = df['title'].str.lower()\n",
    "df['title'] = df['title'].str.split(\" \")\n",
    "\n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.split(\" \")\n",
    "\n",
    "df['text'] = filter(None, df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "for column in ['title', 'text']:\n",
    "    for row in range(0, len(df[column])):\n",
    "    \n",
    "        for element in range(0, len(df[column][row])):\n",
    "            if type(df[column][row][element]) == unicode:\n",
    "                df[column][row][element] = unicodedata.normalize('NFKD', df[column][row][element]).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tekno</td>\n",
       "      <td>[liputan6.com,, jakarta, -, pertumbuhan, start...</td>\n",
       "      <td>[kiat, sukses, berbisnis, teknologi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>[by, eri, komar, sinaga, mantan, kepala, biro,...</td>\n",
       "      <td>[kpk, periksa, politikus, demokrat, terkait, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>[jakarta, -, komisi, pemilihan, umum, (kpu), d...</td>\n",
       "      <td>[pendaftaran, ditutup,, kpu, pastikan, pilgub,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tekno</td>\n",
       "      <td>[arenalte.com, -, perkuat, industri, gaming, y...</td>\n",
       "      <td>[perkuat, industri, gaming,, amd, akuisisi, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>[viva.co.id, -, hingga, senin, malam,, 26, sep...</td>\n",
       "      <td>[bertambah,, korban, tewas, banjir, garut, jad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text  \\\n",
       "0    Tekno  [liputan6.com,, jakarta, -, pertumbuhan, start...   \n",
       "1     News  [by, eri, komar, sinaga, mantan, kepala, biro,...   \n",
       "2     News  [jakarta, -, komisi, pemilihan, umum, (kpu), d...   \n",
       "3    Tekno  [arenalte.com, -, perkuat, industri, gaming, y...   \n",
       "4     News  [viva.co.id, -, hingga, senin, malam,, 26, sep...   \n",
       "\n",
       "                                               title  \n",
       "0               [kiat, sukses, berbisnis, teknologi]  \n",
       "1  [kpk, periksa, politikus, demokrat, terkait, k...  \n",
       "2  [pendaftaran, ditutup,, kpu, pastikan, pilgub,...  \n",
       "3  [perkuat, industri, gaming,, amd, akuisisi, pe...  \n",
       "4  [bertambah,, korban, tewas, banjir, garut, jad...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for column in ['title', 'text']:\n",
    "    for row in range(0, len(df[column])):\n",
    "      \n",
    "        holder = []\n",
    "        \n",
    "        # Reduce data to first 120 words (for performance)\n",
    "        if(column == 'text') and len(df[column][row]) >= 120:\n",
    "          df[column][row] = df[column][row][:120]\n",
    "\n",
    "        for element in range(0, len(df[column][row])):\n",
    "\n",
    "            # Detect escape sequence & unicode\n",
    "\n",
    "            # On head\n",
    "            # Normal regex\n",
    "            if re.match(r\"^\\\\[abfnrtv].*$\", df[column][row][element]) or re.match(r\"^\\\\[\\\\\\'\\\"?].*$\", df[column][row][element]):\n",
    "                print column, row, element\n",
    "                df[column][row][element] = df[column][row][element][2:]\n",
    "\n",
    "            if re.match(r\"^.*\\\\[abfnrtv]$\", df[column][row][element]) or re.match(r\"^.*\\\\[\\\\\\'\\\"?]$\", df[column][row][element]):\n",
    "                df[column][row][element] = df[column][row][element][:-2]\n",
    "\n",
    "            # Detect punctuation\n",
    "\n",
    "            if re.match(r\"^.*[`~!@#$%^&*()_+-=[\\]\\{}|;\\':\\\",.\\/<>?]$\", df[column][row][element]):\n",
    "                df[column][row][element] = df[column][row][element][:-1]\n",
    "\n",
    "            elif re.match(r\"^[`~!@#$%^&*()_+-=[\\]\\{}|;':\\\",.\\/<>?].*$\", df[column][row][element]):\n",
    "                df[column][row][element] = df[column][row][element][1:]\n",
    "\n",
    "\n",
    "            # To be removed or not to be\n",
    "            # Link & number\n",
    "\n",
    "            if df[column][row][element].isdigit() == True or re.match(r\"^.*\\.co.*$\", df[column][row][element]) or re.match(r\"^.*\\.id$\", df[column][row][element]):\n",
    "                holder.append(df[column][row][element])\n",
    "\n",
    "        # Removal Process\n",
    "        for l in holder:\n",
    "            df[column][row].remove(l)\n",
    "\n",
    "        # Filter empty\n",
    "        df[column][row] = filter(None, df[column][row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords_list = []\n",
    "\n",
    "for i in stopwords['stopwords']:\n",
    "    stopwords_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Remove stopwords\n",
    "for category in ['title','text']:\n",
    "    for row in range(0, len(df[category])):\n",
    "        holder = []\n",
    "        \n",
    "        for element in range(0, len(df[category][row])):\n",
    "            if df[category][row][element] in stopwords_list:\n",
    "                holder.append(df[category][row][element])\n",
    "        \n",
    "        for l in holder:\n",
    "            if l in df[category][row]:\n",
    "                df[category][row].remove(l)\n",
    "        \n",
    "        df[column][row] = filter(None, df[column][row])\n",
    "        df[category][row] = \" \".join(df[category][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Cleaning Data\n",
    "### Start Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "labeledDF_title = []\n",
    "labeledDF_text = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    labeledDF_title.append((df['title'][i].lower(), df['category'][i].lower()))\n",
    "    labeledDF_text.append((df['text'][i].lower(), df['category'][i].lower()))\n",
    "    \n",
    "labeledDF_title_train = labeledDF_title[:3200]\n",
    "labeledDF_text_train = labeledDF_text[:3200]\n",
    "\n",
    "labeledDF_title_test = labeledDF_title[3200:]\n",
    "labeledDF_text_test = labeledDF_text[3200:]\n",
    "    \n",
    "print len(labeledDF_title_train) + len(labeledDF_title_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(labeledDF_title_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Building Model\n",
    "\n",
    "### Testing and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title only accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "only_title_accuracy = cl.accuracy(labeledDF_title_test)\n",
    "print \"Title only accuracy: %s\" % (only_title_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content only accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "only_content_accuracy = cl.accuracy(labeledDF_text_test)\n",
    "print \"Content only accuracy: %s\" % (only_content_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# In case databricks broken\n",
    "average_accuracy = ( only_title_accuracy + only_content_accuracy ) / 2\n",
    "print \"Average accuracy: %.2f\" % (average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data_accuracy = cl.accuracy(labeledDF_title_test[start : start + divisor] + labeledDF_text_test[start : start + divisor])\n",
    "print \"Full accuracy: %s\" % (numpy.mean(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Title only accuracy: %s\\nContent only accuracy: %s\\nFull accuracy: %s\" % (only_title_accuracy, only_content_accuracy, full_data_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "news_classify",
  "notebookId": 3519141511945315
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
